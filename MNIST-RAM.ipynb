{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train=mnist.train.num_examples\n",
    "num_val=mnist.validation.images.shape\n",
    "num_test=mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size=64\n",
    "img_size=28\n",
    "sensor_unit=256\n",
    "lstm_size=256\n",
    "N_glimpse=10\n",
    "MC_test=128\n",
    "loc_std=0.2\n",
    "tot_size=batch_size*MC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glimpse_Network():\n",
    "    def __init__(self):\n",
    "        self.glimspe_size=[5,7,9]\n",
    "        self.concat_size=9\n",
    "        self.img_net=tf.layers.Dense(units=sensor_unit,name='glimpse_net/img_net')\n",
    "        self.loc_net=tf.layers.Dense(units=sensor_unit,name='glimpse_net/loc_net')\n",
    "        \n",
    "    def glimpse_sensor(self,image,loc):\n",
    "        glimpses_list=[tf.image.extract_glimpse(input=image,size=[gs,gs],offsets=loc) for gs in self.glimspe_size]\n",
    "        glimpses_norm=[tf.image.resize_bilinear(g,[self.concat_size,self.concat_size]) for g in glimpses_list]\n",
    "        glimpses=tf.concat(values=glimpses_norm,axis=3)  # batch_size*concat_size*concat_size*3\n",
    "        return glimpses\n",
    "    \n",
    "    def forward(self,image,loc):\n",
    "        glimpses=self.glimpse_sensor(image,loc) # tot_size*concat_size*concat_size*3\n",
    "        g_image=self.img_net(inputs=tf.layers.flatten(glimpses))\n",
    "        g_loc=self.loc_net(inputs=loc)\n",
    "        g_out=tf.nn.relu(g_image+g_loc)\n",
    "        return g_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X=tf.placeholder(dtype=tf.float32,shape=[None,28,28,1])\n",
    "y=tf.placeholder(dtype=tf.int64,shape=[None,10])\n",
    "start_location=tf.random_uniform(shape=[tot_size,2],minval=-1.0,maxval=1.0)\n",
    "gNet=Glimpse_Network()\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(lstm_size)\n",
    "state = lstm_cell.zero_state(tot_size, tf.float32)\n",
    "\n",
    "emission_net=tf.layers.Dense(units=2,name='emission_net')\n",
    "baseline_net=tf.layers.Dense(units=1,name='baseline_net')\n",
    "predict_net=tf.layers.Dense(units=10,name='predict_net')\n",
    "\n",
    "def loglikelihood(sample,mean):\n",
    "    gaussian=tf.distributions.Normal(loc=mean,scale=tf.constant([loc_std,loc_std]))\n",
    "    llh=-gaussian.log_prob(sample)\n",
    "    return tf.reduce_sum(llh,axis=1)\n",
    "    \n",
    "loc_his=[]\n",
    "loglikelihood_his=[]\n",
    "baseline_his=[]\n",
    "normalized_loc=start_location\n",
    "for ng in range(N_glimpse):\n",
    "    loc_his.append(normalized_loc)\n",
    "    \n",
    "    # extract glimpse\n",
    "    glimpses_out=gNet.forward(X,normalized_loc)\n",
    "    \n",
    "    # RNN\n",
    "    lstm_output,state=lstm_cell(glimpses_out,state)\n",
    "    \n",
    "    # emit mean of location\n",
    "    loc_mean=emission_net(inputs=lstm_output)\n",
    "    \n",
    "    # sample next location by gaussian distribution centered at loc_mean\n",
    "    loc_sample=tf.random_normal(shape=(tot_size,2),mean=loc_mean,stddev=loc_std)\n",
    "    \n",
    "    # calculate the -loglikelihood of the sampled position\n",
    "    llh=loglikelihood(loc_sample,loc_mean)\n",
    "    loglikelihood_his.append(llh)\n",
    "    \n",
    "    # normalize the location for next input\n",
    "    normalized_loc=tf.tanh(loc_sample)\n",
    "    \n",
    "    # output time independent baseline\n",
    "    baseline=baseline_net(inputs=lstm_output)\n",
    "    baseline_his.append(tf.squeeze(baseline))\n",
    "\n",
    "# pack data for calculation\n",
    "baseline_his=tf.stack(baseline_his)\n",
    "loglikelihood_his=tf.stack(loglikelihood_his)\n",
    "\n",
    "# make prediction\n",
    "score=predict_net(inputs=lstm_output)\n",
    "prediction=tf.argmax(score,1)\n",
    "\n",
    "# calculate reward, do variance reduction and calculate reinforced loglikelihood\n",
    "reward=tf.cast(tf.equal(prediction,tf.argmax(y,1)),dtype=tf.float32)\n",
    "reduce_var_reward=reward-tf.stop_gradient(baseline_his)\n",
    "reinforce_llh=tf.reduce_mean(loglikelihood_his*reduce_var_reward)\n",
    "\n",
    "# regression baseline towards reward\n",
    "baseline_mse=tf.reduce_mean(tf.square(reward-baseline_his))\n",
    "\n",
    "# softmax to output\n",
    "softmax_loss=tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=y,logits=score))\n",
    "\n",
    "# summarize loss\n",
    "loss=reinforce_llh+baseline_mse+softmax_loss\n",
    "\n",
    "\n",
    "optimizier=tf.train.AdamOptimizer(learning_rate=1e-6)\n",
    "train_step = optimizier.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 18:39:00 start epoch 1/100\n",
      "2018-04-13 18:39:01 iter 1 : loss_1 = -0.055326004 loss_2 = 0.15681723 loss_3 = 2.3258123 total_loss = 2.4273036\n",
      "2018-04-13 18:39:12 iter 50 : loss_1 = -0.03875608 loss_2 = 0.1341498 loss_3 = 2.3155053 total_loss = 2.410899\n",
      "2018-04-13 18:39:22 iter 100 : loss_1 = -0.028772796 loss_2 = 0.13506845 loss_3 = 2.3040724 total_loss = 2.410368\n",
      "2018-04-13 18:39:32 iter 150 : loss_1 = -0.021591634 loss_2 = 0.1231664 loss_3 = 2.3270884 total_loss = 2.428663\n",
      "2018-04-13 18:39:43 iter 200 : loss_1 = -0.02415372 loss_2 = 0.12844166 loss_3 = 2.314249 total_loss = 2.418537\n",
      "2018-04-13 18:39:53 iter 250 : loss_1 = -0.03769056 loss_2 = 0.15967295 loss_3 = 2.2869048 total_loss = 2.4088871\n",
      "2018-04-13 18:40:04 iter 300 : loss_1 = -0.039121605 loss_2 = 0.16623122 loss_3 = 2.2905312 total_loss = 2.4176407\n",
      "2018-04-13 18:40:14 iter 350 : loss_1 = -0.020655824 loss_2 = 0.13412912 loss_3 = 2.3145723 total_loss = 2.4280457\n",
      "2018-04-13 18:40:24 iter 400 : loss_1 = -0.0030090595 loss_2 = 0.0979128 loss_3 = 2.3257732 total_loss = 2.420677\n",
      "2018-04-13 18:40:35 iter 450 : loss_1 = -0.0105698835 loss_2 = 0.12246214 loss_3 = 2.2908661 total_loss = 2.4027584\n",
      "2018-04-13 18:40:45 iter 500 : loss_1 = -0.023010412 loss_2 = 0.14370902 loss_3 = 2.2940865 total_loss = 2.4147851\n",
      "2018-04-13 18:40:56 iter 550 : loss_1 = -0.00048592137 loss_2 = 0.10140381 loss_3 = 2.308124 total_loss = 2.409042\n",
      "2018-04-13 18:41:06 iter 600 : loss_1 = -0.008785109 loss_2 = 0.1182585 loss_3 = 2.2984505 total_loss = 2.407924\n",
      "2018-04-13 18:41:16 iter 650 : loss_1 = -0.03408861 loss_2 = 0.16694006 loss_3 = 2.2789192 total_loss = 2.4117706\n",
      "2018-04-13 18:41:27 iter 700 : loss_1 = -0.03444126 loss_2 = 0.17230912 loss_3 = 2.2635505 total_loss = 2.4014184\n",
      "2018-04-13 18:41:37 iter 750 : loss_1 = -0.027895123 loss_2 = 0.16306297 loss_3 = 2.2673264 total_loss = 2.4024942\n",
      "2018-04-13 18:41:48 iter 800 : loss_1 = -0.014503539 loss_2 = 0.14202192 loss_3 = 2.2838988 total_loss = 2.4114172\n",
      "2018-04-13 18:41:58 iter 850 : loss_1 = -0.024344517 loss_2 = 0.15490852 loss_3 = 2.2664704 total_loss = 2.3970344\n",
      "2018-04-13 18:42:00 iter 859 : loss_1 = -0.024509933 loss_2 = 0.15923238 loss_3 = 2.271884 total_loss = 2.4066064\n",
      "2018-04-13 18:42:00 end epoch, average loss = 2.4146398165728353\n",
      "2018-04-13 18:42:00 start epoch 2/100\n",
      "2018-04-13 18:42:00 iter 1 : loss_1 = -0.041771777 loss_2 = 0.19681747 loss_3 = 2.2542453 total_loss = 2.409291\n",
      "2018-04-13 18:42:11 iter 50 : loss_1 = -0.021871988 loss_2 = 0.15889649 loss_3 = 2.267559 total_loss = 2.4045835\n",
      "2018-04-13 18:42:21 iter 100 : loss_1 = -0.013662738 loss_2 = 0.14560106 loss_3 = 2.2735097 total_loss = 2.405448\n",
      "2018-04-13 18:42:31 iter 150 : loss_1 = -0.014134223 loss_2 = 0.15223941 loss_3 = 2.2666073 total_loss = 2.4047124\n",
      "2018-04-13 18:42:42 iter 200 : loss_1 = -0.018960115 loss_2 = 0.16493455 loss_3 = 2.2601018 total_loss = 2.4060762\n",
      "2018-04-13 18:42:52 iter 250 : loss_1 = -0.042790443 loss_2 = 0.20520897 loss_3 = 2.253634 total_loss = 2.4160526\n",
      "2018-04-13 18:43:03 iter 300 : loss_1 = -0.022954224 loss_2 = 0.17950295 loss_3 = 2.2605336 total_loss = 2.4170823\n",
      "2018-04-13 18:43:13 iter 350 : loss_1 = -0.02150926 loss_2 = 0.18043323 loss_3 = 2.251381 total_loss = 2.4103048\n",
      "2018-04-13 18:43:24 iter 400 : loss_1 = -0.038525473 loss_2 = 0.20998521 loss_3 = 2.2412882 total_loss = 2.4127479\n",
      "2018-04-13 18:43:34 iter 450 : loss_1 = -0.030709833 loss_2 = 0.19797452 loss_3 = 2.2396743 total_loss = 2.406939\n",
      "2018-04-13 18:43:45 iter 500 : loss_1 = -0.038143046 loss_2 = 0.20803718 loss_3 = 2.2353778 total_loss = 2.405272\n",
      "2018-04-13 18:43:55 iter 550 : loss_1 = -0.027806347 loss_2 = 0.19755211 loss_3 = 2.256479 total_loss = 2.4262247\n",
      "2018-04-13 18:44:06 iter 600 : loss_1 = -0.031029582 loss_2 = 0.20270905 loss_3 = 2.2495198 total_loss = 2.4211993\n",
      "2018-04-13 18:44:16 iter 650 : loss_1 = -0.054130353 loss_2 = 0.23840085 loss_3 = 2.2191558 total_loss = 2.4034262\n",
      "2018-04-13 18:44:26 iter 700 : loss_1 = -0.028103286 loss_2 = 0.20645384 loss_3 = 2.2286167 total_loss = 2.4069672\n",
      "2018-04-13 18:44:37 iter 750 : loss_1 = -0.019166427 loss_2 = 0.19724563 loss_3 = 2.2382772 total_loss = 2.4163563\n",
      "2018-04-13 18:44:47 iter 800 : loss_1 = -0.020236563 loss_2 = 0.2048563 loss_3 = 2.2328775 total_loss = 2.4174972\n",
      "2018-04-13 18:44:58 iter 850 : loss_1 = -0.031736903 loss_2 = 0.2165587 loss_3 = 2.2235963 total_loss = 2.4084182\n",
      "2018-04-13 18:44:59 iter 859 : loss_1 = -0.033513196 loss_2 = 0.2238179 loss_3 = 2.2202034 total_loss = 2.4105082\n",
      "2018-04-13 18:44:59 end epoch, average loss = 2.411234134289938\n",
      "2018-04-13 18:44:59 start epoch 3/100\n",
      "2018-04-13 18:45:00 iter 1 : loss_1 = -0.015684608 loss_2 = 0.20250285 loss_3 = 2.2255185 total_loss = 2.4123368\n",
      "2018-04-13 18:45:10 iter 50 : loss_1 = -0.028942015 loss_2 = 0.21803093 loss_3 = 2.2284913 total_loss = 2.4175801\n",
      "2018-04-13 18:45:20 iter 100 : loss_1 = -0.0008522024 loss_2 = 0.18912594 loss_3 = 2.2368052 total_loss = 2.4250789\n",
      "2018-04-13 18:45:31 iter 150 : loss_1 = -0.055264473 loss_2 = 0.24994306 loss_3 = 2.1987414 total_loss = 2.39342\n",
      "2018-04-13 18:45:41 iter 200 : loss_1 = -0.037928957 loss_2 = 0.23332465 loss_3 = 2.2115288 total_loss = 2.4069245\n",
      "2018-04-13 18:45:52 iter 250 : loss_1 = -0.0325027 loss_2 = 0.22411449 loss_3 = 2.214852 total_loss = 2.4064639\n",
      "2018-04-13 18:46:02 iter 300 : loss_1 = -0.025227899 loss_2 = 0.21714091 loss_3 = 2.2159119 total_loss = 2.407825\n",
      "2018-04-13 18:46:13 iter 350 : loss_1 = -0.027428985 loss_2 = 0.22492667 loss_3 = 2.2155826 total_loss = 2.4130802\n",
      "2018-04-13 18:46:23 iter 400 : loss_1 = -0.015093654 loss_2 = 0.21098962 loss_3 = 2.2227607 total_loss = 2.4186566\n",
      "2018-04-13 18:46:33 iter 450 : loss_1 = -0.045643564 loss_2 = 0.24532425 loss_3 = 2.178241 total_loss = 2.3779216\n",
      "2018-04-13 18:46:44 iter 500 : loss_1 = -0.023993034 loss_2 = 0.22689167 loss_3 = 2.1955836 total_loss = 2.3984823\n",
      "2018-04-13 18:46:54 iter 550 : loss_1 = -0.03368486 loss_2 = 0.23457232 loss_3 = 2.1946921 total_loss = 2.3955796\n",
      "2018-04-13 18:47:05 iter 600 : loss_1 = -0.035187684 loss_2 = 0.23719268 loss_3 = 2.1793437 total_loss = 2.3813486\n",
      "2018-04-13 18:47:15 iter 650 : loss_1 = -0.01763453 loss_2 = 0.22602324 loss_3 = 2.1898003 total_loss = 2.398189\n",
      "2018-04-13 18:47:26 iter 700 : loss_1 = -0.022985857 loss_2 = 0.22660813 loss_3 = 2.1920354 total_loss = 2.3956578\n",
      "2018-04-13 18:47:36 iter 750 : loss_1 = -0.010941381 loss_2 = 0.21216817 loss_3 = 2.1972404 total_loss = 2.398467\n",
      "2018-04-13 18:47:47 iter 800 : loss_1 = -0.012345988 loss_2 = 0.21817665 loss_3 = 2.1936054 total_loss = 2.399436\n",
      "2018-04-13 18:47:57 iter 850 : loss_1 = -0.031867396 loss_2 = 0.23454604 loss_3 = 2.1589274 total_loss = 2.3616061\n",
      "2018-04-13 18:47:59 iter 859 : loss_1 = -0.029936338 loss_2 = 0.2385098 loss_3 = 2.1777177 total_loss = 2.386291\n",
      "2018-04-13 18:47:59 end epoch, average loss = 2.3968099259941624\n",
      "2018-04-13 18:47:59 start epoch 4/100\n",
      "2018-04-13 18:47:59 iter 1 : loss_1 = -0.031727962 loss_2 = 0.23541288 loss_3 = 2.1528234 total_loss = 2.3565083\n",
      "2018-04-13 18:48:10 iter 50 : loss_1 = -0.039873812 loss_2 = 0.24427071 loss_3 = 2.1643107 total_loss = 2.3687077\n",
      "2018-04-13 18:48:20 iter 100 : loss_1 = -0.026288617 loss_2 = 0.22763316 loss_3 = 2.170155 total_loss = 2.3714995\n",
      "2018-04-13 18:48:31 iter 150 : loss_1 = -0.01782703 loss_2 = 0.21988781 loss_3 = 2.174214 total_loss = 2.3762746\n",
      "2018-04-13 18:48:41 iter 200 : loss_1 = -0.03453491 loss_2 = 0.2408824 loss_3 = 2.1656563 total_loss = 2.3720038\n",
      "2018-04-13 18:48:52 iter 250 : loss_1 = -0.034056365 loss_2 = 0.23764244 loss_3 = 2.153207 total_loss = 2.3567932\n",
      "2018-04-13 18:49:02 iter 300 : loss_1 = -0.05694629 loss_2 = 0.26010126 loss_3 = 2.1272874 total_loss = 2.3304424\n",
      "2018-04-13 18:49:12 iter 350 : loss_1 = -0.043222494 loss_2 = 0.2494627 loss_3 = 2.126613 total_loss = 2.332853\n",
      "2018-04-13 18:49:23 iter 400 : loss_1 = -0.035235025 loss_2 = 0.23683977 loss_3 = 2.1627479 total_loss = 2.3643527\n",
      "2018-04-13 18:49:33 iter 450 : loss_1 = -0.03405111 loss_2 = 0.24182066 loss_3 = 2.1504369 total_loss = 2.3582065\n",
      "2018-04-13 18:49:44 iter 500 : loss_1 = -0.044216298 loss_2 = 0.24776173 loss_3 = 2.129357 total_loss = 2.3329024\n",
      "2018-04-13 18:49:54 iter 550 : loss_1 = -0.040541284 loss_2 = 0.24622698 loss_3 = 2.1247997 total_loss = 2.3304853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 18:50:04 iter 600 : loss_1 = -0.03037629 loss_2 = 0.24028563 loss_3 = 2.1479075 total_loss = 2.357817\n",
      "2018-04-13 18:50:15 iter 650 : loss_1 = -0.015234714 loss_2 = 0.23176336 loss_3 = 2.1507587 total_loss = 2.3672874\n",
      "2018-04-13 18:50:25 iter 700 : loss_1 = -0.017314034 loss_2 = 0.2280232 loss_3 = 2.1563177 total_loss = 2.3670268\n",
      "2018-04-13 18:50:36 iter 750 : loss_1 = -0.013461946 loss_2 = 0.23351666 loss_3 = 2.1352973 total_loss = 2.355352\n",
      "2018-04-13 18:50:46 iter 800 : loss_1 = -0.027532807 loss_2 = 0.23548241 loss_3 = 2.118918 total_loss = 2.3268676\n",
      "2018-04-13 18:50:57 iter 850 : loss_1 = -0.008855047 loss_2 = 0.22237507 loss_3 = 2.1432023 total_loss = 2.3567224\n",
      "2018-04-13 18:50:58 iter 859 : loss_1 = -0.04012896 loss_2 = 0.24921879 loss_3 = 2.1141462 total_loss = 2.323236\n",
      "2018-04-13 18:50:58 end epoch, average loss = 2.3532611596570443\n",
      "2018-04-13 18:50:58 start epoch 5/100\n",
      "2018-04-13 18:50:59 iter 1 : loss_1 = -0.020074796 loss_2 = 0.2318038 loss_3 = 2.1240907 total_loss = 2.3358197\n",
      "2018-04-13 18:51:09 iter 50 : loss_1 = 0.008616774 loss_2 = 0.20752135 loss_3 = 2.163343 total_loss = 2.379481\n",
      "2018-04-13 18:51:19 iter 100 : loss_1 = -0.042673863 loss_2 = 0.24965033 loss_3 = 2.0904198 total_loss = 2.2973962\n",
      "2018-04-13 18:51:30 iter 150 : loss_1 = -0.029200133 loss_2 = 0.24295545 loss_3 = 2.1097288 total_loss = 2.3234842\n",
      "2018-04-13 18:51:40 iter 200 : loss_1 = -0.0401255 loss_2 = 0.25049242 loss_3 = 2.0750864 total_loss = 2.2854533\n",
      "2018-04-13 18:51:50 iter 250 : loss_1 = -0.025490876 loss_2 = 0.23965581 loss_3 = 2.1053095 total_loss = 2.3194745\n",
      "2018-04-13 18:52:01 iter 300 : loss_1 = -0.026646039 loss_2 = 0.24509902 loss_3 = 2.111461 total_loss = 2.3299139\n",
      "2018-04-13 18:52:11 iter 350 : loss_1 = -0.027321234 loss_2 = 0.23724313 loss_3 = 2.1027508 total_loss = 2.3126726\n",
      "2018-04-13 18:52:22 iter 400 : loss_1 = -0.0307044 loss_2 = 0.24603467 loss_3 = 2.092248 total_loss = 2.3075783\n",
      "2018-04-13 18:52:32 iter 450 : loss_1 = -0.039909136 loss_2 = 0.25233844 loss_3 = 2.0907989 total_loss = 2.3032281\n",
      "2018-04-13 18:52:42 iter 500 : loss_1 = -0.042255603 loss_2 = 0.24940363 loss_3 = 2.0834289 total_loss = 2.290577\n",
      "2018-04-13 18:52:53 iter 550 : loss_1 = -0.026321411 loss_2 = 0.24591522 loss_3 = 2.0643244 total_loss = 2.2839181\n",
      "2018-04-13 18:53:03 iter 600 : loss_1 = -0.03020449 loss_2 = 0.24166901 loss_3 = 2.050027 total_loss = 2.2614913\n",
      "2018-04-13 18:53:14 iter 650 : loss_1 = -0.01837965 loss_2 = 0.24828549 loss_3 = 2.0791283 total_loss = 2.309034\n",
      "2018-04-13 18:53:24 iter 700 : loss_1 = -0.020866139 loss_2 = 0.2379405 loss_3 = 2.0684786 total_loss = 2.285553\n",
      "2018-04-13 18:53:35 iter 750 : loss_1 = -0.03367444 loss_2 = 0.24499743 loss_3 = 2.0466623 total_loss = 2.2579854\n",
      "2018-04-13 18:53:45 iter 800 : loss_1 = -0.060425468 loss_2 = 0.2685138 loss_3 = 2.0088246 total_loss = 2.216913\n",
      "2018-04-13 18:53:55 iter 850 : loss_1 = -0.030973738 loss_2 = 0.24004082 loss_3 = 2.0678873 total_loss = 2.2769544\n",
      "2018-04-13 18:53:57 iter 859 : loss_1 = -0.045644246 loss_2 = 0.25734144 loss_3 = 2.0077908 total_loss = 2.219488\n",
      "2018-04-13 18:53:57 end epoch, average loss = 2.300759524211062\n",
      "2018-04-13 18:53:57 start epoch 6/100\n",
      "2018-04-13 18:53:58 iter 1 : loss_1 = -0.044601195 loss_2 = 0.25839254 loss_3 = 2.0260684 total_loss = 2.2398598\n",
      "2018-04-13 18:54:08 iter 50 : loss_1 = -0.03478188 loss_2 = 0.2448597 loss_3 = 2.0431988 total_loss = 2.2532766\n",
      "2018-04-13 18:54:18 iter 100 : loss_1 = -0.053227525 loss_2 = 0.24941579 loss_3 = 2.022725 total_loss = 2.2189133\n",
      "2018-04-13 18:54:29 iter 150 : loss_1 = -0.019036626 loss_2 = 0.2336194 loss_3 = 2.0635786 total_loss = 2.2781613\n",
      "2018-04-13 18:54:39 iter 200 : loss_1 = -0.016933322 loss_2 = 0.2448606 loss_3 = 2.0594285 total_loss = 2.2873557\n",
      "2018-04-13 18:54:50 iter 250 : loss_1 = -0.024713079 loss_2 = 0.23859653 loss_3 = 2.012114 total_loss = 2.2259974\n",
      "2018-04-13 18:55:00 iter 300 : loss_1 = -0.018270502 loss_2 = 0.23525839 loss_3 = 2.0584555 total_loss = 2.2754433\n",
      "2018-04-13 18:55:10 iter 350 : loss_1 = -0.007275589 loss_2 = 0.23052797 loss_3 = 2.085062 total_loss = 2.3083143\n",
      "2018-04-13 18:55:21 iter 400 : loss_1 = -0.0076685785 loss_2 = 0.23302612 loss_3 = 2.05968 total_loss = 2.2850375\n",
      "2018-04-13 18:55:31 iter 450 : loss_1 = -0.021255802 loss_2 = 0.23139223 loss_3 = 2.042006 total_loss = 2.2521424\n",
      "2018-04-13 18:55:42 iter 500 : loss_1 = -0.05352536 loss_2 = 0.25401843 loss_3 = 1.9978387 total_loss = 2.1983318\n",
      "2018-04-13 18:55:52 iter 550 : loss_1 = -0.025642216 loss_2 = 0.24248691 loss_3 = 2.0391695 total_loss = 2.2560143\n",
      "2018-04-13 18:56:03 iter 600 : loss_1 = -0.023439337 loss_2 = 0.23555008 loss_3 = 2.014019 total_loss = 2.2261298\n",
      "2018-04-13 18:56:13 iter 650 : loss_1 = -0.033789553 loss_2 = 0.24076073 loss_3 = 1.9921685 total_loss = 2.1991396\n",
      "2018-04-13 18:56:24 iter 700 : loss_1 = -0.03603973 loss_2 = 0.24541566 loss_3 = 1.992307 total_loss = 2.2016828\n",
      "2018-04-13 18:56:34 iter 750 : loss_1 = -0.019332718 loss_2 = 0.23545432 loss_3 = 2.0437086 total_loss = 2.2598302\n",
      "2018-04-13 18:56:45 iter 800 : loss_1 = -0.04059534 loss_2 = 0.25363532 loss_3 = 1.9838748 total_loss = 2.1969147\n",
      "2018-04-13 18:56:55 iter 850 : loss_1 = -0.014680815 loss_2 = 0.2355822 loss_3 = 2.020001 total_loss = 2.2409024\n",
      "2018-04-13 18:56:57 iter 859 : loss_1 = -0.031093532 loss_2 = 0.23609722 loss_3 = 2.005596 total_loss = 2.2105997\n",
      "2018-04-13 18:56:57 end epoch, average loss = 2.249725946863816\n",
      "2018-04-13 18:56:57 start epoch 7/100\n",
      "2018-04-13 18:56:57 iter 1 : loss_1 = -0.005829636 loss_2 = 0.22469702 loss_3 = 2.029666 total_loss = 2.2485332\n",
      "2018-04-13 18:57:08 iter 50 : loss_1 = -0.020015582 loss_2 = 0.23651752 loss_3 = 2.0143685 total_loss = 2.2308705\n",
      "2018-04-13 18:57:18 iter 100 : loss_1 = -0.033068415 loss_2 = 0.252111 loss_3 = 1.9977618 total_loss = 2.2168045\n",
      "2018-04-13 18:57:28 iter 150 : loss_1 = -0.01651921 loss_2 = 0.23641518 loss_3 = 1.9846607 total_loss = 2.2045567\n",
      "2018-04-13 18:57:39 iter 200 : loss_1 = -0.015222254 loss_2 = 0.24177095 loss_3 = 2.0070398 total_loss = 2.2335885\n",
      "2018-04-13 18:57:49 iter 250 : loss_1 = -0.029781159 loss_2 = 0.24995689 loss_3 = 1.9722153 total_loss = 2.192391\n",
      "2018-04-13 18:58:00 iter 300 : loss_1 = -0.019733083 loss_2 = 0.25186625 loss_3 = 2.0026271 total_loss = 2.2347603\n",
      "2018-04-13 18:58:10 iter 350 : loss_1 = -0.0032751628 loss_2 = 0.22896008 loss_3 = 2.03993 total_loss = 2.265615\n",
      "2018-04-13 18:58:20 iter 400 : loss_1 = 0.0017318234 loss_2 = 0.21816263 loss_3 = 2.0238316 total_loss = 2.243726\n",
      "2018-04-13 18:58:31 iter 450 : loss_1 = -0.02001681 loss_2 = 0.24991599 loss_3 = 2.009873 total_loss = 2.239772\n",
      "2018-04-13 18:58:41 iter 500 : loss_1 = -0.021659764 loss_2 = 0.2312103 loss_3 = 1.9926224 total_loss = 2.202173\n",
      "2018-04-13 18:58:52 iter 550 : loss_1 = -0.018176692 loss_2 = 0.2334651 loss_3 = 1.9711963 total_loss = 2.1864848\n",
      "2018-04-13 18:59:02 iter 600 : loss_1 = -0.0060236007 loss_2 = 0.22819135 loss_3 = 1.995743 total_loss = 2.2179108\n",
      "2018-04-13 18:59:13 iter 650 : loss_1 = -0.010140793 loss_2 = 0.22500186 loss_3 = 1.9976958 total_loss = 2.2125568\n",
      "2018-04-13 18:59:23 iter 700 : loss_1 = -0.002950856 loss_2 = 0.22542319 loss_3 = 2.0340242 total_loss = 2.2564967\n",
      "2018-04-13 18:59:33 iter 750 : loss_1 = -0.02881999 loss_2 = 0.23941095 loss_3 = 1.9602214 total_loss = 2.1708124\n",
      "2018-04-13 18:59:44 iter 800 : loss_1 = -0.01129367 loss_2 = 0.23055092 loss_3 = 2.0177293 total_loss = 2.2369866\n",
      "2018-04-13 18:59:54 iter 850 : loss_1 = 0.00794051 loss_2 = 0.22767949 loss_3 = 2.064133 total_loss = 2.299753\n",
      "2018-04-13 18:59:56 iter 859 : loss_1 = -0.01328176 loss_2 = 0.23873062 loss_3 = 1.9784616 total_loss = 2.2039106\n",
      "2018-04-13 18:59:56 end epoch, average loss = 2.2204906535231888\n",
      "2018-04-13 18:59:56 start epoch 8/100\n",
      "2018-04-13 18:59:56 iter 1 : loss_1 = -0.043495554 loss_2 = 0.24981093 loss_3 = 1.9463301 total_loss = 2.1526453\n",
      "2018-04-13 19:00:07 iter 50 : loss_1 = -0.022489492 loss_2 = 0.23170707 loss_3 = 1.9991535 total_loss = 2.2083712\n",
      "2018-04-13 19:00:17 iter 100 : loss_1 = -0.020918291 loss_2 = 0.23596859 loss_3 = 1.9319054 total_loss = 2.1469557\n",
      "2018-04-13 19:00:27 iter 150 : loss_1 = -0.02745096 loss_2 = 0.23070753 loss_3 = 1.9792284 total_loss = 2.1824849\n",
      "2018-04-13 19:00:38 iter 200 : loss_1 = -0.018339898 loss_2 = 0.23614426 loss_3 = 1.9658961 total_loss = 2.1837006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 19:00:48 iter 250 : loss_1 = -0.01551086 loss_2 = 0.23249622 loss_3 = 1.9861124 total_loss = 2.2030978\n",
      "2018-04-13 19:00:59 iter 300 : loss_1 = -0.0018654246 loss_2 = 0.21926527 loss_3 = 2.02346 total_loss = 2.2408597\n",
      "2018-04-13 19:01:09 iter 350 : loss_1 = 0.0051425556 loss_2 = 0.21801524 loss_3 = 2.0309238 total_loss = 2.2540817\n",
      "2018-04-13 19:01:20 iter 400 : loss_1 = -0.02603564 loss_2 = 0.24226587 loss_3 = 2.0163126 total_loss = 2.2325428\n",
      "2018-04-13 19:01:30 iter 450 : loss_1 = 0.018486302 loss_2 = 0.21162936 loss_3 = 2.0783114 total_loss = 2.308427\n",
      "2018-04-13 19:01:41 iter 500 : loss_1 = -0.012742212 loss_2 = 0.22957441 loss_3 = 2.012807 total_loss = 2.229639\n",
      "2018-04-13 19:01:51 iter 550 : loss_1 = -0.0037573054 loss_2 = 0.2246943 loss_3 = 2.0031836 total_loss = 2.2241206\n",
      "2018-04-13 19:02:02 iter 600 : loss_1 = -0.0072469325 loss_2 = 0.21943025 loss_3 = 2.0141907 total_loss = 2.226374\n",
      "2018-04-13 19:02:12 iter 650 : loss_1 = -0.03132675 loss_2 = 0.2370646 loss_3 = 1.952904 total_loss = 2.1586418\n",
      "2018-04-13 19:02:23 iter 700 : loss_1 = -0.020379987 loss_2 = 0.23411998 loss_3 = 1.9616443 total_loss = 2.1753843\n",
      "2018-04-13 19:02:34 iter 750 : loss_1 = -0.017833758 loss_2 = 0.24221735 loss_3 = 1.9686968 total_loss = 2.1930804\n",
      "2018-04-13 19:02:44 iter 800 : loss_1 = -0.021915521 loss_2 = 0.23115726 loss_3 = 1.9912031 total_loss = 2.2004447\n",
      "2018-04-13 19:02:55 iter 850 : loss_1 = -0.01770711 loss_2 = 0.23106787 loss_3 = 2.012879 total_loss = 2.2262397\n",
      "2018-04-13 19:02:56 iter 859 : loss_1 = 0.009144156 loss_2 = 0.21179776 loss_3 = 2.0587678 total_loss = 2.2797098\n",
      "2018-04-13 19:02:56 end epoch, average loss = 2.21221997962703\n",
      "2018-04-13 19:02:56 start epoch 9/100\n",
      "2018-04-13 19:02:57 iter 1 : loss_1 = -0.023732377 loss_2 = 0.23643017 loss_3 = 1.9493437 total_loss = 2.1620414\n",
      "2018-04-13 19:03:07 iter 50 : loss_1 = -0.035731234 loss_2 = 0.24404564 loss_3 = 1.9428613 total_loss = 2.1511757\n",
      "2018-04-13 19:03:17 iter 100 : loss_1 = -0.012232805 loss_2 = 0.23120889 loss_3 = 1.9986138 total_loss = 2.2175899\n",
      "2018-04-13 19:03:28 iter 150 : loss_1 = 0.022550717 loss_2 = 0.20187612 loss_3 = 2.1104774 total_loss = 2.3349042\n",
      "2018-04-13 19:03:38 iter 200 : loss_1 = -0.015967142 loss_2 = 0.2237657 loss_3 = 2.0143495 total_loss = 2.222148\n",
      "2018-04-13 19:03:49 iter 250 : loss_1 = 0.009661807 loss_2 = 0.22263093 loss_3 = 2.062636 total_loss = 2.2949286\n",
      "2018-04-13 19:04:00 iter 300 : loss_1 = -0.0010573014 loss_2 = 0.21604171 loss_3 = 2.0217676 total_loss = 2.236752\n",
      "2018-04-13 19:04:10 iter 350 : loss_1 = -0.002664804 loss_2 = 0.21837907 loss_3 = 1.9927256 total_loss = 2.2084398\n",
      "2018-04-13 19:04:20 iter 400 : loss_1 = -0.0057687694 loss_2 = 0.2285405 loss_3 = 2.0238848 total_loss = 2.2466564\n",
      "2018-04-13 19:04:31 iter 450 : loss_1 = 0.0011006908 loss_2 = 0.22445956 loss_3 = 2.071888 total_loss = 2.2974482\n",
      "2018-04-13 19:04:42 iter 500 : loss_1 = -0.031686652 loss_2 = 0.2448186 loss_3 = 2.012677 total_loss = 2.2258089\n",
      "2018-04-13 19:04:52 iter 550 : loss_1 = -0.022625383 loss_2 = 0.22804852 loss_3 = 1.996985 total_loss = 2.202408\n",
      "2018-04-13 19:05:02 iter 600 : loss_1 = -0.0072959303 loss_2 = 0.2263467 loss_3 = 2.0271933 total_loss = 2.246244\n",
      "2018-04-13 19:05:13 iter 650 : loss_1 = 0.020438204 loss_2 = 0.19844286 loss_3 = 2.0458608 total_loss = 2.264742\n",
      "2018-04-13 19:05:23 iter 700 : loss_1 = -0.0062191975 loss_2 = 0.21763206 loss_3 = 1.9946537 total_loss = 2.2060666\n",
      "2018-04-13 19:05:34 iter 750 : loss_1 = -0.001989623 loss_2 = 0.20882833 loss_3 = 2.021919 total_loss = 2.2287576\n",
      "2018-04-13 19:05:44 iter 800 : loss_1 = -0.03158803 loss_2 = 0.2382863 loss_3 = 1.9696047 total_loss = 2.176303\n",
      "2018-04-13 19:05:55 iter 850 : loss_1 = -0.019496609 loss_2 = 0.23062448 loss_3 = 1.9631339 total_loss = 2.1742618\n",
      "2018-04-13 19:05:57 iter 859 : loss_1 = 0.0029950226 loss_2 = 0.2190475 loss_3 = 2.0211253 total_loss = 2.2431679\n",
      "2018-04-13 19:05:57 end epoch, average loss = 2.21386469368052\n",
      "2018-04-13 19:05:57 start epoch 10/100\n",
      "2018-04-13 19:05:57 iter 1 : loss_1 = -0.014415102 loss_2 = 0.22210138 loss_3 = 1.973003 total_loss = 2.1806893\n",
      "2018-04-13 19:06:07 iter 50 : loss_1 = 0.007312483 loss_2 = 0.20805256 loss_3 = 2.0546865 total_loss = 2.2700515\n",
      "2018-04-13 19:06:18 iter 100 : loss_1 = 0.000598873 loss_2 = 0.20939155 loss_3 = 2.059772 total_loss = 2.2697625\n",
      "2018-04-13 19:06:28 iter 150 : loss_1 = -0.022218073 loss_2 = 0.22412157 loss_3 = 2.0016747 total_loss = 2.2035782\n",
      "2018-04-13 19:06:39 iter 200 : loss_1 = -0.027932003 loss_2 = 0.23541002 loss_3 = 1.9479681 total_loss = 2.155446\n",
      "2018-04-13 19:06:49 iter 250 : loss_1 = 0.012541631 loss_2 = 0.1965572 loss_3 = 2.101603 total_loss = 2.3107018\n",
      "2018-04-13 19:07:00 iter 300 : loss_1 = 0.020613158 loss_2 = 0.20719182 loss_3 = 2.0848434 total_loss = 2.3126483\n",
      "2018-04-13 19:07:10 iter 350 : loss_1 = -0.018716872 loss_2 = 0.2264388 loss_3 = 1.9805311 total_loss = 2.188253\n",
      "2018-04-13 19:07:21 iter 400 : loss_1 = 0.007049809 loss_2 = 0.20530395 loss_3 = 2.0197148 total_loss = 2.2320685\n",
      "2018-04-13 19:07:31 iter 450 : loss_1 = -0.034265745 loss_2 = 0.24521661 loss_3 = 1.9295104 total_loss = 2.1404612\n",
      "2018-04-13 19:07:42 iter 500 : loss_1 = -0.019559393 loss_2 = 0.23578627 loss_3 = 1.9486302 total_loss = 2.1648571\n",
      "2018-04-13 19:07:52 iter 550 : loss_1 = -0.00030095316 loss_2 = 0.20429428 loss_3 = 2.0723286 total_loss = 2.276322\n",
      "2018-04-13 19:08:03 iter 600 : loss_1 = -0.0055166194 loss_2 = 0.21553688 loss_3 = 2.0147758 total_loss = 2.224796\n",
      "2018-04-13 19:08:13 iter 650 : loss_1 = -0.03161688 loss_2 = 0.23781165 loss_3 = 1.9765303 total_loss = 2.1827252\n",
      "2018-04-13 19:08:24 iter 700 : loss_1 = -0.015451545 loss_2 = 0.21793064 loss_3 = 1.987967 total_loss = 2.1904461\n",
      "2018-04-13 19:08:34 iter 750 : loss_1 = -0.008364324 loss_2 = 0.2210027 loss_3 = 2.0181475 total_loss = 2.2307858\n",
      "2018-04-13 19:08:45 iter 800 : loss_1 = -0.003711893 loss_2 = 0.21661322 loss_3 = 2.0456843 total_loss = 2.2585857\n",
      "2018-04-13 19:08:56 iter 850 : loss_1 = -0.011807616 loss_2 = 0.22623393 loss_3 = 2.0157185 total_loss = 2.2301447\n",
      "2018-04-13 19:08:58 iter 859 : loss_1 = -0.027333478 loss_2 = 0.23238115 loss_3 = 1.9692101 total_loss = 2.1742578\n",
      "2018-04-13 19:08:58 end epoch, average loss = 2.213513784552897\n",
      "2018-04-13 19:08:58 start epoch 11/100\n",
      "2018-04-13 19:08:58 iter 1 : loss_1 = -0.026979214 loss_2 = 0.22460565 loss_3 = 1.9605889 total_loss = 2.1582153\n",
      "2018-04-13 19:09:08 iter 50 : loss_1 = -0.03420534 loss_2 = 0.23555812 loss_3 = 1.9542224 total_loss = 2.1555753\n",
      "2018-04-13 19:09:19 iter 100 : loss_1 = -0.0034031533 loss_2 = 0.22375235 loss_3 = 2.0022237 total_loss = 2.2225728\n",
      "2018-04-13 19:09:29 iter 150 : loss_1 = -0.018594721 loss_2 = 0.23448375 loss_3 = 1.9287963 total_loss = 2.1446853\n",
      "2018-04-13 19:09:40 iter 200 : loss_1 = -0.007743557 loss_2 = 0.21715584 loss_3 = 2.0027015 total_loss = 2.2121139\n",
      "2018-04-13 19:09:51 iter 250 : loss_1 = 0.008561271 loss_2 = 0.20548785 loss_3 = 2.0326104 total_loss = 2.2466595\n",
      "2018-04-13 19:10:01 iter 300 : loss_1 = -0.0041183615 loss_2 = 0.21934743 loss_3 = 1.9780165 total_loss = 2.1932456\n",
      "2018-04-13 19:10:12 iter 350 : loss_1 = -0.015352326 loss_2 = 0.21984652 loss_3 = 1.947502 total_loss = 2.1519961\n",
      "2018-04-13 19:10:22 iter 400 : loss_1 = 0.001379835 loss_2 = 0.21281262 loss_3 = 2.0177646 total_loss = 2.231957\n",
      "2018-04-13 19:10:33 iter 450 : loss_1 = 0.01642729 loss_2 = 0.21027613 loss_3 = 2.0397258 total_loss = 2.2664292\n",
      "2018-04-13 19:10:43 iter 500 : loss_1 = -0.03155248 loss_2 = 0.24436656 loss_3 = 1.9311777 total_loss = 2.1439917\n",
      "2018-04-13 19:10:54 iter 550 : loss_1 = 0.011327526 loss_2 = 0.19893795 loss_3 = 2.0302734 total_loss = 2.2405388\n",
      "2018-04-13 19:11:04 iter 600 : loss_1 = -0.0070638107 loss_2 = 0.23120925 loss_3 = 1.9701667 total_loss = 2.194312\n",
      "2018-04-13 19:11:15 iter 650 : loss_1 = 0.018358696 loss_2 = 0.19949286 loss_3 = 2.0795503 total_loss = 2.297402\n",
      "2018-04-13 19:11:25 iter 700 : loss_1 = -0.0015151696 loss_2 = 0.21996212 loss_3 = 2.0255902 total_loss = 2.2440372\n",
      "2018-04-13 19:11:36 iter 750 : loss_1 = 0.0076093944 loss_2 = 0.2074405 loss_3 = 2.0250757 total_loss = 2.2401257\n",
      "2018-04-13 19:11:47 iter 800 : loss_1 = -0.0058066873 loss_2 = 0.22474942 loss_3 = 2.0091143 total_loss = 2.228057\n",
      "2018-04-13 19:11:57 iter 850 : loss_1 = -0.008878237 loss_2 = 0.23133853 loss_3 = 1.9801767 total_loss = 2.202637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 19:11:59 iter 859 : loss_1 = 0.0037964755 loss_2 = 0.20830555 loss_3 = 1.9899135 total_loss = 2.2020154\n",
      "2018-04-13 19:11:59 end epoch, average loss = 2.204590381371406\n",
      "2018-04-13 19:11:59 start epoch 12/100\n",
      "2018-04-13 19:11:59 iter 1 : loss_1 = -0.019462049 loss_2 = 0.22582126 loss_3 = 1.9883912 total_loss = 2.1947503\n",
      "2018-04-13 19:12:10 iter 50 : loss_1 = -0.014454904 loss_2 = 0.2291849 loss_3 = 1.9781506 total_loss = 2.1928806\n",
      "2018-04-13 19:12:20 iter 100 : loss_1 = -0.013904506 loss_2 = 0.22119336 loss_3 = 1.973253 total_loss = 2.1805418\n",
      "2018-04-13 19:12:31 iter 150 : loss_1 = -0.012217127 loss_2 = 0.2192277 loss_3 = 2.0176237 total_loss = 2.2246342\n",
      "2018-04-13 19:12:41 iter 200 : loss_1 = -0.025270632 loss_2 = 0.23630567 loss_3 = 1.9488223 total_loss = 2.1598573\n",
      "2018-04-13 19:12:52 iter 250 : loss_1 = -0.027992744 loss_2 = 0.24050418 loss_3 = 1.9443772 total_loss = 2.1568887\n",
      "2018-04-13 19:13:03 iter 300 : loss_1 = -0.0012562476 loss_2 = 0.21612544 loss_3 = 1.999311 total_loss = 2.2141802\n",
      "2018-04-13 19:13:13 iter 350 : loss_1 = -0.002059062 loss_2 = 0.21944246 loss_3 = 1.9719148 total_loss = 2.1892982\n",
      "2018-04-13 19:13:24 iter 400 : loss_1 = -0.016228424 loss_2 = 0.22868223 loss_3 = 1.9737402 total_loss = 2.186194\n",
      "2018-04-13 19:13:35 iter 450 : loss_1 = 0.0008260658 loss_2 = 0.20803623 loss_3 = 2.0157566 total_loss = 2.224619\n",
      "2018-04-13 19:13:45 iter 500 : loss_1 = -0.02631097 loss_2 = 0.23716633 loss_3 = 1.9198151 total_loss = 2.1306705\n",
      "2018-04-13 19:13:56 iter 550 : loss_1 = -0.013320066 loss_2 = 0.2346776 loss_3 = 1.9437833 total_loss = 2.1651409\n",
      "2018-04-13 19:14:07 iter 600 : loss_1 = -0.014345804 loss_2 = 0.2304099 loss_3 = 1.9537084 total_loss = 2.1697726\n",
      "2018-04-13 19:14:17 iter 650 : loss_1 = -0.013746093 loss_2 = 0.22774701 loss_3 = 1.9693619 total_loss = 2.1833627\n",
      "2018-04-13 19:14:28 iter 700 : loss_1 = -0.0049257353 loss_2 = 0.21717653 loss_3 = 1.9895439 total_loss = 2.2017946\n",
      "2018-04-13 19:14:38 iter 750 : loss_1 = -0.019182414 loss_2 = 0.22981331 loss_3 = 1.9348347 total_loss = 2.1454656\n",
      "2018-04-13 19:14:49 iter 800 : loss_1 = -0.011172566 loss_2 = 0.22234277 loss_3 = 1.9791456 total_loss = 2.190316\n",
      "2018-04-13 19:15:00 iter 850 : loss_1 = -0.019393485 loss_2 = 0.22487912 loss_3 = 1.9540374 total_loss = 2.159523\n",
      "2018-04-13 19:15:02 iter 859 : loss_1 = 0.0014131765 loss_2 = 0.21487145 loss_3 = 1.9586025 total_loss = 2.1748872\n",
      "2018-04-13 19:15:02 end epoch, average loss = 2.1924439675594236\n",
      "2018-04-13 19:15:02 start epoch 13/100\n",
      "2018-04-13 19:15:02 iter 1 : loss_1 = -0.020266779 loss_2 = 0.22636425 loss_3 = 1.9929409 total_loss = 2.1990385\n",
      "2018-04-13 19:15:12 iter 50 : loss_1 = -0.0027705242 loss_2 = 0.21954823 loss_3 = 1.9761316 total_loss = 2.1929092\n",
      "2018-04-13 19:15:23 iter 100 : loss_1 = 0.014625629 loss_2 = 0.1998975 loss_3 = 2.0770113 total_loss = 2.2915344\n",
      "2018-04-13 19:15:34 iter 150 : loss_1 = -0.0024664276 loss_2 = 0.21448784 loss_3 = 1.9798186 total_loss = 2.19184\n",
      "2018-04-13 19:15:44 iter 200 : loss_1 = -0.008062422 loss_2 = 0.22527432 loss_3 = 1.947028 total_loss = 2.16424\n",
      "2018-04-13 19:15:55 iter 250 : loss_1 = -0.028955227 loss_2 = 0.24365965 loss_3 = 1.9267113 total_loss = 2.1414158\n",
      "2018-04-13 19:16:06 iter 300 : loss_1 = -0.0045914287 loss_2 = 0.21907198 loss_3 = 1.9832124 total_loss = 2.1976929\n",
      "2018-04-13 19:16:17 iter 350 : loss_1 = 0.002274909 loss_2 = 0.2128801 loss_3 = 1.9825448 total_loss = 2.1976998\n",
      "2018-04-13 19:16:28 iter 400 : loss_1 = -0.0096868295 loss_2 = 0.2180661 loss_3 = 1.9565529 total_loss = 2.1649323\n",
      "2018-04-13 19:16:38 iter 450 : loss_1 = -0.016287263 loss_2 = 0.234198 loss_3 = 1.9518721 total_loss = 2.1697829\n",
      "2018-04-13 19:16:49 iter 500 : loss_1 = -0.00019326675 loss_2 = 0.22010052 loss_3 = 2.0065813 total_loss = 2.2264886\n",
      "2018-04-13 19:17:00 iter 550 : loss_1 = -0.0076068332 loss_2 = 0.2221632 loss_3 = 1.9828538 total_loss = 2.19741\n",
      "2018-04-13 19:17:10 iter 600 : loss_1 = -0.001911802 loss_2 = 0.21322206 loss_3 = 2.0060277 total_loss = 2.2173378\n",
      "2018-04-13 19:17:21 iter 650 : loss_1 = -0.0366684 loss_2 = 0.24346557 loss_3 = 1.8925349 total_loss = 2.099332\n",
      "2018-04-13 19:17:32 iter 700 : loss_1 = -0.0038490961 loss_2 = 0.21698347 loss_3 = 1.9815428 total_loss = 2.194677\n",
      "2018-04-13 19:17:43 iter 750 : loss_1 = -0.008916635 loss_2 = 0.22295597 loss_3 = 1.9617393 total_loss = 2.1757786\n",
      "2018-04-13 19:17:54 iter 800 : loss_1 = -0.011804364 loss_2 = 0.22293177 loss_3 = 2.0160563 total_loss = 2.2271838\n",
      "2018-04-13 19:18:05 iter 850 : loss_1 = -0.011891903 loss_2 = 0.23100781 loss_3 = 1.9294276 total_loss = 2.1485436\n",
      "2018-04-13 19:18:06 iter 859 : loss_1 = -0.0176506 loss_2 = 0.23369284 loss_3 = 1.9464393 total_loss = 2.1624815\n",
      "2018-04-13 19:18:06 end epoch, average loss = 2.1812729174932586\n",
      "2018-04-13 19:18:06 start epoch 14/100\n",
      "2018-04-13 19:18:07 iter 1 : loss_1 = 0.0013466814 loss_2 = 0.21497087 loss_3 = 1.9838046 total_loss = 2.200122\n",
      "2018-04-13 19:18:17 iter 50 : loss_1 = -0.015359284 loss_2 = 0.2290612 loss_3 = 1.9374121 total_loss = 2.151114\n",
      "2018-04-13 19:18:28 iter 100 : loss_1 = 0.0051548816 loss_2 = 0.21266499 loss_3 = 1.9601355 total_loss = 2.1779554\n",
      "2018-04-13 19:18:39 iter 150 : loss_1 = -0.027438289 loss_2 = 0.23973508 loss_3 = 1.9285607 total_loss = 2.1408575\n",
      "2018-04-13 19:18:50 iter 200 : loss_1 = 0.020411788 loss_2 = 0.20408586 loss_3 = 2.0039606 total_loss = 2.2284582\n",
      "2018-04-13 19:19:01 iter 250 : loss_1 = -0.0050940765 loss_2 = 0.2237629 loss_3 = 1.9417567 total_loss = 2.1604257\n",
      "2018-04-13 19:19:12 iter 300 : loss_1 = -0.027421594 loss_2 = 0.24230742 loss_3 = 1.8807414 total_loss = 2.0956273\n",
      "2018-04-13 19:19:23 iter 350 : loss_1 = -0.014736084 loss_2 = 0.22241144 loss_3 = 1.9807539 total_loss = 2.1884294\n",
      "2018-04-13 19:19:34 iter 400 : loss_1 = -0.019399453 loss_2 = 0.22895026 loss_3 = 1.931701 total_loss = 2.1412518\n",
      "2018-04-13 19:19:45 iter 450 : loss_1 = 0.0075888024 loss_2 = 0.20634468 loss_3 = 2.0150127 total_loss = 2.2289462\n",
      "2018-04-13 19:19:56 iter 500 : loss_1 = -0.04997421 loss_2 = 0.25904772 loss_3 = 1.8757223 total_loss = 2.0847957\n",
      "2018-04-13 19:20:07 iter 550 : loss_1 = -0.016921148 loss_2 = 0.22590728 loss_3 = 1.9116523 total_loss = 2.1206384\n",
      "2018-04-13 19:20:18 iter 600 : loss_1 = -0.02436312 loss_2 = 0.23819904 loss_3 = 1.9271157 total_loss = 2.1409516\n",
      "2018-04-13 19:20:29 iter 650 : loss_1 = -0.0052564614 loss_2 = 0.23249507 loss_3 = 1.9373534 total_loss = 2.164592\n",
      "2018-04-13 19:20:40 iter 700 : loss_1 = -0.016414497 loss_2 = 0.22604331 loss_3 = 1.9394772 total_loss = 2.149106\n",
      "2018-04-13 19:20:52 iter 750 : loss_1 = -0.024026087 loss_2 = 0.22981966 loss_3 = 1.9115487 total_loss = 2.1173422\n",
      "2018-04-13 19:21:03 iter 800 : loss_1 = -0.012563886 loss_2 = 0.22012457 loss_3 = 1.9434485 total_loss = 2.1510093\n",
      "2018-04-13 19:21:14 iter 850 : loss_1 = -0.00024086688 loss_2 = 0.22093812 loss_3 = 1.9566848 total_loss = 2.177382\n",
      "2018-04-13 19:21:16 iter 859 : loss_1 = 0.011094024 loss_2 = 0.20693591 loss_3 = 1.9987907 total_loss = 2.2168207\n",
      "2018-04-13 19:21:16 end epoch, average loss = 2.169618165257091\n",
      "2018-04-13 19:21:16 start epoch 15/100\n",
      "2018-04-13 19:21:16 iter 1 : loss_1 = -0.024719533 loss_2 = 0.24113312 loss_3 = 1.9082823 total_loss = 2.1246958\n",
      "2018-04-13 19:21:27 iter 50 : loss_1 = -0.01885306 loss_2 = 0.2313054 loss_3 = 1.9619495 total_loss = 2.1744018\n",
      "2018-04-13 19:21:38 iter 100 : loss_1 = -0.028367251 loss_2 = 0.23605141 loss_3 = 1.9048526 total_loss = 2.112537\n",
      "2018-04-13 19:21:49 iter 150 : loss_1 = -0.018779302 loss_2 = 0.23263296 loss_3 = 1.9073715 total_loss = 2.121225\n",
      "2018-04-13 19:22:00 iter 200 : loss_1 = -0.01272097 loss_2 = 0.22434655 loss_3 = 1.9731333 total_loss = 2.184759\n",
      "2018-04-13 19:22:11 iter 250 : loss_1 = 0.0032697406 loss_2 = 0.20970288 loss_3 = 1.9905032 total_loss = 2.2034757\n",
      "2018-04-13 19:22:23 iter 300 : loss_1 = 0.0006498676 loss_2 = 0.21586108 loss_3 = 1.9336026 total_loss = 2.1501136\n",
      "2018-04-13 19:22:34 iter 350 : loss_1 = -0.017594341 loss_2 = 0.2283628 loss_3 = 1.9582772 total_loss = 2.1690457\n",
      "2018-04-13 19:22:45 iter 400 : loss_1 = -0.018691257 loss_2 = 0.22635083 loss_3 = 1.9423167 total_loss = 2.1499763\n",
      "2018-04-13 19:22:56 iter 450 : loss_1 = -0.0053142533 loss_2 = 0.21774288 loss_3 = 1.9408276 total_loss = 2.1532562\n",
      "2018-04-13 19:23:07 iter 500 : loss_1 = -0.004372644 loss_2 = 0.21766646 loss_3 = 1.9661303 total_loss = 2.179424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 19:23:18 iter 550 : loss_1 = -0.033322595 loss_2 = 0.24497333 loss_3 = 1.8435125 total_loss = 2.0551634\n",
      "2018-04-13 19:23:30 iter 600 : loss_1 = 0.0072070984 loss_2 = 0.2113719 loss_3 = 1.9898062 total_loss = 2.2083852\n",
      "2018-04-13 19:23:41 iter 650 : loss_1 = -0.008256571 loss_2 = 0.22490224 loss_3 = 1.9353552 total_loss = 2.152001\n",
      "2018-04-13 19:23:53 iter 700 : loss_1 = 0.007913722 loss_2 = 0.20637059 loss_3 = 1.9356592 total_loss = 2.1499436\n",
      "2018-04-13 19:24:04 iter 750 : loss_1 = 0.00020046005 loss_2 = 0.21247001 loss_3 = 1.9564221 total_loss = 2.1690927\n",
      "2018-04-13 19:24:15 iter 800 : loss_1 = -0.01684562 loss_2 = 0.23090371 loss_3 = 1.89007 total_loss = 2.1041281\n",
      "2018-04-13 19:24:27 iter 850 : loss_1 = -0.021455605 loss_2 = 0.23513587 loss_3 = 1.89012 total_loss = 2.1038003\n",
      "2018-04-13 19:24:29 iter 859 : loss_1 = -0.004628774 loss_2 = 0.21159232 loss_3 = 1.9468842 total_loss = 2.1538477\n",
      "2018-04-13 19:24:29 end epoch, average loss = 2.160622043298759\n",
      "2018-04-13 19:24:29 start epoch 16/100\n",
      "2018-04-13 19:24:29 iter 1 : loss_1 = 0.00072171446 loss_2 = 0.21288595 loss_3 = 1.9861217 total_loss = 2.1997292\n",
      "2018-04-13 19:24:41 iter 50 : loss_1 = -0.020548113 loss_2 = 0.23101382 loss_3 = 1.8853214 total_loss = 2.095787\n",
      "2018-04-13 19:24:52 iter 100 : loss_1 = 0.01587149 loss_2 = 0.20732498 loss_3 = 1.9433504 total_loss = 2.1665468\n",
      "2018-04-13 19:25:03 iter 150 : loss_1 = -0.033465642 loss_2 = 0.24046107 loss_3 = 1.9291779 total_loss = 2.1361732\n",
      "2018-04-13 19:25:15 iter 200 : loss_1 = -0.016473893 loss_2 = 0.22236903 loss_3 = 1.9430839 total_loss = 2.148979\n",
      "2018-04-13 19:25:26 iter 250 : loss_1 = -0.018206557 loss_2 = 0.2241818 loss_3 = 1.8997009 total_loss = 2.1056762\n",
      "2018-04-13 19:25:38 iter 300 : loss_1 = -0.015696153 loss_2 = 0.22641191 loss_3 = 1.931231 total_loss = 2.1419468\n",
      "2018-04-13 19:25:50 iter 350 : loss_1 = 0.0024870888 loss_2 = 0.20878796 loss_3 = 2.0519137 total_loss = 2.2631888\n",
      "2018-04-13 19:26:01 iter 400 : loss_1 = -0.0067180893 loss_2 = 0.22126302 loss_3 = 1.9583795 total_loss = 2.1729245\n",
      "2018-04-13 19:26:13 iter 450 : loss_1 = -0.0062484993 loss_2 = 0.21616392 loss_3 = 1.9751655 total_loss = 2.185081\n",
      "2018-04-13 19:26:25 iter 500 : loss_1 = -0.011650976 loss_2 = 0.21843949 loss_3 = 1.9744728 total_loss = 2.1812613\n",
      "2018-04-13 19:26:36 iter 550 : loss_1 = -0.031436536 loss_2 = 0.24159393 loss_3 = 1.8561711 total_loss = 2.0663285\n",
      "2018-04-13 19:26:48 iter 600 : loss_1 = -0.00092331524 loss_2 = 0.21135971 loss_3 = 1.9620806 total_loss = 2.172517\n",
      "2018-04-13 19:27:00 iter 650 : loss_1 = -0.029332098 loss_2 = 0.23627982 loss_3 = 1.854974 total_loss = 2.0619218\n",
      "2018-04-13 19:27:12 iter 700 : loss_1 = -0.0109233875 loss_2 = 0.223328 loss_3 = 1.943822 total_loss = 2.1562266\n",
      "2018-04-13 19:27:24 iter 750 : loss_1 = -0.026814356 loss_2 = 0.2370874 loss_3 = 1.8992206 total_loss = 2.1094937\n",
      "2018-04-13 19:27:36 iter 800 : loss_1 = -0.026281621 loss_2 = 0.23744488 loss_3 = 1.913739 total_loss = 2.1249022\n",
      "2018-04-13 19:27:47 iter 850 : loss_1 = -0.019701267 loss_2 = 0.22911835 loss_3 = 1.8837574 total_loss = 2.0931745\n",
      "2018-04-13 19:27:50 iter 859 : loss_1 = -0.0027848545 loss_2 = 0.21705362 loss_3 = 1.9518361 total_loss = 2.1661048\n",
      "2018-04-13 19:27:50 end epoch, average loss = 2.1558029099310096\n",
      "2018-04-13 19:27:50 start epoch 17/100\n",
      "2018-04-13 19:27:50 iter 1 : loss_1 = -0.0031309526 loss_2 = 0.21007137 loss_3 = 1.9781342 total_loss = 2.1850746\n",
      "2018-04-13 19:28:02 iter 50 : loss_1 = 0.011763063 loss_2 = 0.19939145 loss_3 = 2.0068007 total_loss = 2.217955\n",
      "2018-04-13 19:28:14 iter 100 : loss_1 = -0.0178163 loss_2 = 0.2217423 loss_3 = 1.9001825 total_loss = 2.1041086\n",
      "2018-04-13 19:28:26 iter 150 : loss_1 = 0.00026644097 loss_2 = 0.20796816 loss_3 = 1.9887978 total_loss = 2.1970325\n",
      "2018-04-13 19:28:38 iter 200 : loss_1 = -0.021365548 loss_2 = 0.2252349 loss_3 = 1.8886104 total_loss = 2.0924797\n",
      "2018-04-13 19:28:50 iter 250 : loss_1 = -0.0024544008 loss_2 = 0.21172717 loss_3 = 1.9667184 total_loss = 2.1759913\n",
      "2018-04-13 19:29:02 iter 300 : loss_1 = 0.0007301887 loss_2 = 0.20652218 loss_3 = 2.0266569 total_loss = 2.2339091\n",
      "2018-04-13 19:29:14 iter 350 : loss_1 = -0.0072570867 loss_2 = 0.2188539 loss_3 = 1.9692931 total_loss = 2.1808898\n",
      "2018-04-13 19:29:26 iter 400 : loss_1 = -0.030300116 loss_2 = 0.23315391 loss_3 = 1.8884411 total_loss = 2.0912948\n",
      "2018-04-13 19:29:38 iter 450 : loss_1 = -0.032593966 loss_2 = 0.23645139 loss_3 = 1.9138417 total_loss = 2.1176991\n",
      "2018-04-13 19:29:50 iter 500 : loss_1 = 8.313525e-05 loss_2 = 0.20662132 loss_3 = 1.9875304 total_loss = 2.1942348\n",
      "2018-04-13 19:30:02 iter 550 : loss_1 = 0.0034492076 loss_2 = 0.20483164 loss_3 = 2.001723 total_loss = 2.2100039\n",
      "2018-04-13 19:30:14 iter 600 : loss_1 = -0.006034228 loss_2 = 0.21013431 loss_3 = 1.9455605 total_loss = 2.1496606\n",
      "2018-04-13 19:30:27 iter 650 : loss_1 = -0.009447761 loss_2 = 0.2184887 loss_3 = 1.9685361 total_loss = 2.177577\n",
      "2018-04-13 19:30:39 iter 700 : loss_1 = -0.0108363265 loss_2 = 0.21037228 loss_3 = 1.9410355 total_loss = 2.1405714\n",
      "2018-04-13 19:30:51 iter 750 : loss_1 = -0.024781626 loss_2 = 0.22904734 loss_3 = 1.9106247 total_loss = 2.1148906\n",
      "2018-04-13 19:31:03 iter 800 : loss_1 = -0.014571488 loss_2 = 0.22115748 loss_3 = 1.9410415 total_loss = 2.1476274\n",
      "2018-04-13 19:31:16 iter 850 : loss_1 = -0.02527216 loss_2 = 0.2313405 loss_3 = 1.8828158 total_loss = 2.088884\n",
      "2018-04-13 19:31:18 iter 859 : loss_1 = 0.0024222874 loss_2 = 0.2024034 loss_3 = 1.9910277 total_loss = 2.1958535\n",
      "2018-04-13 19:31:18 end epoch, average loss = 2.15825278517531\n",
      "2018-04-13 19:31:18 start epoch 18/100\n",
      "2018-04-13 19:31:18 iter 1 : loss_1 = 0.001614818 loss_2 = 0.20204136 loss_3 = 1.9916382 total_loss = 2.1952944\n",
      "2018-04-13 19:31:30 iter 50 : loss_1 = -0.020053316 loss_2 = 0.2253006 loss_3 = 1.9519851 total_loss = 2.1572323\n",
      "2018-04-13 19:31:43 iter 100 : loss_1 = -0.02459867 loss_2 = 0.22290996 loss_3 = 1.9520278 total_loss = 2.1503391\n",
      "2018-04-13 19:31:55 iter 150 : loss_1 = -0.02157006 loss_2 = 0.22844414 loss_3 = 1.9213057 total_loss = 2.1281798\n",
      "2018-04-13 19:32:08 iter 200 : loss_1 = -0.0022705472 loss_2 = 0.21072654 loss_3 = 1.958339 total_loss = 2.166795\n",
      "2018-04-13 19:32:21 iter 250 : loss_1 = 0.020594612 loss_2 = 0.18860558 loss_3 = 2.0548015 total_loss = 2.2640016\n",
      "2018-04-13 19:32:33 iter 300 : loss_1 = 0.0009318263 loss_2 = 0.20526342 loss_3 = 1.9942266 total_loss = 2.2004218\n",
      "2018-04-13 19:32:46 iter 350 : loss_1 = -0.006996949 loss_2 = 0.21077347 loss_3 = 1.9748151 total_loss = 2.1785917\n",
      "2018-04-13 19:32:59 iter 400 : loss_1 = -0.015068695 loss_2 = 0.2141715 loss_3 = 1.9535748 total_loss = 2.1526775\n",
      "2018-04-13 19:33:11 iter 450 : loss_1 = -0.004633027 loss_2 = 0.20688665 loss_3 = 1.9545393 total_loss = 2.1567929\n",
      "2018-04-13 19:33:24 iter 500 : loss_1 = -0.020360846 loss_2 = 0.2271783 loss_3 = 1.9162638 total_loss = 2.1230812\n",
      "2018-04-13 19:33:37 iter 550 : loss_1 = -0.026289305 loss_2 = 0.22859097 loss_3 = 1.9367142 total_loss = 2.139016\n",
      "2018-04-13 19:33:50 iter 600 : loss_1 = -0.00014053937 loss_2 = 0.20336111 loss_3 = 1.9771593 total_loss = 2.1803799\n",
      "2018-04-13 19:34:03 iter 650 : loss_1 = -0.03544746 loss_2 = 0.23447052 loss_3 = 1.8710009 total_loss = 2.070024\n",
      "2018-04-13 19:34:16 iter 700 : loss_1 = 0.0053260047 loss_2 = 0.19442171 loss_3 = 1.9964077 total_loss = 2.1961555\n",
      "2018-04-13 19:34:29 iter 750 : loss_1 = -0.009919772 loss_2 = 0.21073875 loss_3 = 1.9911046 total_loss = 2.1919236\n",
      "2018-04-13 19:34:42 iter 800 : loss_1 = 0.00048353797 loss_2 = 0.20272025 loss_3 = 1.9675083 total_loss = 2.170712\n",
      "2018-04-13 19:34:54 iter 850 : loss_1 = -0.011874283 loss_2 = 0.21488032 loss_3 = 1.9346437 total_loss = 2.1376498\n",
      "2018-04-13 19:34:57 iter 859 : loss_1 = -0.010768052 loss_2 = 0.20749572 loss_3 = 1.9985931 total_loss = 2.1953208\n",
      "2018-04-13 19:34:57 end epoch, average loss = 2.166315466755344\n",
      "2018-04-13 19:34:57 start epoch 19/100\n",
      "2018-04-13 19:34:57 iter 1 : loss_1 = 0.0052628233 loss_2 = 0.19892287 loss_3 = 2.001172 total_loss = 2.2053578\n",
      "2018-04-13 19:35:10 iter 50 : loss_1 = -0.009598901 loss_2 = 0.20776415 loss_3 = 1.9073138 total_loss = 2.105479\n",
      "2018-04-13 19:35:23 iter 100 : loss_1 = 0.013632139 loss_2 = 0.18958688 loss_3 = 2.0245304 total_loss = 2.2277493\n",
      "2018-04-13 19:35:36 iter 150 : loss_1 = 0.006657891 loss_2 = 0.1953648 loss_3 = 1.9959135 total_loss = 2.1979363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 19:35:50 iter 200 : loss_1 = -0.015965674 loss_2 = 0.2145046 loss_3 = 1.9182682 total_loss = 2.1168072\n",
      "2018-04-13 19:36:03 iter 250 : loss_1 = -0.009621205 loss_2 = 0.20566913 loss_3 = 2.0228932 total_loss = 2.2189412\n",
      "2018-04-13 19:36:16 iter 300 : loss_1 = 0.011320075 loss_2 = 0.18608221 loss_3 = 2.0502934 total_loss = 2.2476957\n",
      "2018-04-13 19:36:29 iter 350 : loss_1 = -0.01118616 loss_2 = 0.21149588 loss_3 = 2.0016527 total_loss = 2.2019625\n",
      "2018-04-13 19:36:42 iter 400 : loss_1 = 0.0027131303 loss_2 = 0.20021844 loss_3 = 1.9764624 total_loss = 2.179394\n",
      "2018-04-13 19:36:55 iter 450 : loss_1 = 0.0077846595 loss_2 = 0.19166443 loss_3 = 1.9893612 total_loss = 2.1888103\n",
      "2018-04-13 19:37:09 iter 500 : loss_1 = -0.022807816 loss_2 = 0.2206494 loss_3 = 1.9727962 total_loss = 2.1706378\n",
      "2018-04-13 19:37:22 iter 550 : loss_1 = -0.016110841 loss_2 = 0.20824723 loss_3 = 1.9744029 total_loss = 2.1665392\n",
      "2018-04-13 19:37:35 iter 600 : loss_1 = -0.014000619 loss_2 = 0.20532775 loss_3 = 1.9677899 total_loss = 2.159117\n",
      "2018-04-13 19:37:49 iter 650 : loss_1 = -0.02750836 loss_2 = 0.22716317 loss_3 = 1.8805172 total_loss = 2.080172\n",
      "2018-04-13 19:38:02 iter 700 : loss_1 = -0.013630381 loss_2 = 0.21502435 loss_3 = 1.9652569 total_loss = 2.166651\n",
      "2018-04-13 19:38:15 iter 750 : loss_1 = -0.009773007 loss_2 = 0.20577502 loss_3 = 1.9848542 total_loss = 2.1808562\n",
      "2018-04-13 19:38:29 iter 800 : loss_1 = -0.0029502227 loss_2 = 0.19629642 loss_3 = 2.0175698 total_loss = 2.210916\n",
      "2018-04-13 19:38:42 iter 850 : loss_1 = 0.003995277 loss_2 = 0.19502342 loss_3 = 2.0146499 total_loss = 2.2136686\n",
      "2018-04-13 19:38:45 iter 859 : loss_1 = -0.023997337 loss_2 = 0.21837917 loss_3 = 1.9172521 total_loss = 2.1116338\n",
      "2018-04-13 19:38:45 end epoch, average loss = 2.1809465557649057\n",
      "2018-04-13 19:38:45 start epoch 20/100\n",
      "2018-04-13 19:38:45 iter 1 : loss_1 = -0.0027683733 loss_2 = 0.20103452 loss_3 = 2.0083427 total_loss = 2.2066088\n",
      "2018-04-13 19:38:58 iter 50 : loss_1 = -0.011685643 loss_2 = 0.21780196 loss_3 = 1.9462764 total_loss = 2.1523929\n",
      "2018-04-13 19:39:12 iter 100 : loss_1 = -0.020589381 loss_2 = 0.21235745 loss_3 = 1.9571266 total_loss = 2.1488948\n",
      "2018-04-13 19:39:26 iter 150 : loss_1 = -0.028663557 loss_2 = 0.21964324 loss_3 = 1.8845494 total_loss = 2.075529\n",
      "2018-04-13 19:39:39 iter 200 : loss_1 = 0.0058455733 loss_2 = 0.18799296 loss_3 = 2.0058293 total_loss = 2.199668\n",
      "2018-04-13 19:39:53 iter 250 : loss_1 = -0.009435348 loss_2 = 0.20048265 loss_3 = 1.9934952 total_loss = 2.1845427\n",
      "2018-04-13 19:40:07 iter 300 : loss_1 = -0.03516604 loss_2 = 0.22451015 loss_3 = 1.9068913 total_loss = 2.0962355\n",
      "2018-04-13 19:40:21 iter 350 : loss_1 = -0.015480733 loss_2 = 0.20107588 loss_3 = 1.9913256 total_loss = 2.176921\n",
      "2018-04-13 19:40:35 iter 400 : loss_1 = 0.005683893 loss_2 = 0.19599381 loss_3 = 1.9970723 total_loss = 2.19875\n",
      "2018-04-13 19:40:48 iter 450 : loss_1 = -0.014493601 loss_2 = 0.20717497 loss_3 = 2.020749 total_loss = 2.2134304\n",
      "2018-04-13 19:41:02 iter 500 : loss_1 = 0.011083066 loss_2 = 0.1788778 loss_3 = 2.075874 total_loss = 2.265835\n",
      "2018-04-13 19:41:16 iter 550 : loss_1 = 0.012387199 loss_2 = 0.17652075 loss_3 = 2.0285125 total_loss = 2.2174203\n",
      "2018-04-13 19:41:30 iter 600 : loss_1 = 0.007985391 loss_2 = 0.18563399 loss_3 = 2.045541 total_loss = 2.2391605\n",
      "2018-04-13 19:41:44 iter 650 : loss_1 = -0.02673704 loss_2 = 0.21800026 loss_3 = 1.9516952 total_loss = 2.1429584\n",
      "2018-04-13 19:41:58 iter 700 : loss_1 = -0.00089684065 loss_2 = 0.19326237 loss_3 = 1.9998387 total_loss = 2.1922042\n",
      "2018-04-13 19:42:12 iter 750 : loss_1 = 0.0038254955 loss_2 = 0.1836349 loss_3 = 2.0267544 total_loss = 2.2142148\n",
      "2018-04-13 19:42:26 iter 800 : loss_1 = 0.0044963593 loss_2 = 0.18664905 loss_3 = 2.0100265 total_loss = 2.2011719\n",
      "2018-04-13 19:42:40 iter 850 : loss_1 = -0.008416412 loss_2 = 0.19888993 loss_3 = 2.0299113 total_loss = 2.2203848\n",
      "2018-04-13 19:42:42 iter 859 : loss_1 = -0.012811318 loss_2 = 0.2010545 loss_3 = 2.0164263 total_loss = 2.2046695\n",
      "2018-04-13 19:42:42 end epoch, average loss = 2.1926196481906772\n",
      "2018-04-13 19:42:42 start epoch 21/100\n",
      "2018-04-13 19:42:43 iter 1 : loss_1 = 0.020732373 loss_2 = 0.18298155 loss_3 = 2.0800617 total_loss = 2.2837756\n",
      "2018-04-13 19:42:57 iter 50 : loss_1 = -0.011216184 loss_2 = 0.20775342 loss_3 = 2.0182834 total_loss = 2.2148206\n",
      "2018-04-13 19:43:11 iter 100 : loss_1 = 0.004578222 loss_2 = 0.19071117 loss_3 = 1.9991426 total_loss = 2.194432\n",
      "2018-04-13 19:43:25 iter 150 : loss_1 = -0.027474988 loss_2 = 0.22297046 loss_3 = 1.9003499 total_loss = 2.0958452\n",
      "2018-04-13 19:43:39 iter 200 : loss_1 = -0.0033989237 loss_2 = 0.1922539 loss_3 = 2.0006986 total_loss = 2.1895535\n",
      "2018-04-13 19:43:53 iter 250 : loss_1 = -0.006926185 loss_2 = 0.1989325 loss_3 = 2.0220206 total_loss = 2.214027\n",
      "2018-04-13 19:44:07 iter 300 : loss_1 = -0.009939393 loss_2 = 0.19825462 loss_3 = 1.9969059 total_loss = 2.1852212\n",
      "2018-04-13 19:44:21 iter 350 : loss_1 = 0.0054924637 loss_2 = 0.18427017 loss_3 = 2.0318213 total_loss = 2.2215838\n",
      "2018-04-13 19:44:35 iter 400 : loss_1 = -0.014077634 loss_2 = 0.20321055 loss_3 = 2.0178118 total_loss = 2.2069447\n",
      "2018-04-13 19:44:49 iter 450 : loss_1 = -0.003699549 loss_2 = 0.19527566 loss_3 = 2.0144653 total_loss = 2.2060413\n",
      "2018-04-13 19:45:03 iter 500 : loss_1 = -0.007844743 loss_2 = 0.20013845 loss_3 = 2.0166125 total_loss = 2.2089062\n",
      "2018-04-13 19:45:18 iter 550 : loss_1 = -0.004879997 loss_2 = 0.19598207 loss_3 = 2.072653 total_loss = 2.263755\n",
      "2018-04-13 19:45:32 iter 600 : loss_1 = -0.021771822 loss_2 = 0.20499134 loss_3 = 1.9896084 total_loss = 2.172828\n",
      "2018-04-13 19:45:46 iter 650 : loss_1 = 0.004362414 loss_2 = 0.18289235 loss_3 = 2.0473127 total_loss = 2.2345674\n",
      "2018-04-13 19:46:01 iter 700 : loss_1 = 0.006746523 loss_2 = 0.18383801 loss_3 = 2.0413542 total_loss = 2.2319388\n",
      "2018-04-13 19:46:15 iter 750 : loss_1 = -0.0053952876 loss_2 = 0.19648117 loss_3 = 2.0111856 total_loss = 2.2022715\n",
      "2018-04-13 19:46:29 iter 800 : loss_1 = -0.0037797154 loss_2 = 0.19115189 loss_3 = 2.071012 total_loss = 2.2583842\n",
      "2018-04-13 19:46:44 iter 850 : loss_1 = 0.0024784692 loss_2 = 0.19009261 loss_3 = 2.062103 total_loss = 2.2546742\n",
      "2018-04-13 19:46:46 iter 859 : loss_1 = 0.0008143928 loss_2 = 0.19129375 loss_3 = 1.9985945 total_loss = 2.1907027\n",
      "2018-04-13 19:46:46 end epoch, average loss = 2.199795282206241\n",
      "2018-04-13 19:46:46 start epoch 22/100\n",
      "2018-04-13 19:46:47 iter 1 : loss_1 = -0.022025242 loss_2 = 0.20760599 loss_3 = 1.9871745 total_loss = 2.1727552\n",
      "2018-04-13 19:47:01 iter 50 : loss_1 = -0.017232783 loss_2 = 0.20680292 loss_3 = 1.9518561 total_loss = 2.1414263\n",
      "2018-04-13 19:47:15 iter 100 : loss_1 = 0.0017531321 loss_2 = 0.18257204 loss_3 = 2.0363874 total_loss = 2.2207127\n",
      "2018-04-13 19:47:29 iter 150 : loss_1 = -0.012856184 loss_2 = 0.20194206 loss_3 = 2.0105267 total_loss = 2.1996126\n",
      "2018-04-13 19:47:44 iter 200 : loss_1 = 0.00016579758 loss_2 = 0.18863387 loss_3 = 2.0002584 total_loss = 2.189058\n",
      "2018-04-13 19:47:58 iter 250 : loss_1 = -0.0046063135 loss_2 = 0.19304447 loss_3 = 2.0338583 total_loss = 2.2222965\n",
      "2018-04-13 19:48:12 iter 300 : loss_1 = 0.005726423 loss_2 = 0.18436536 loss_3 = 2.0210233 total_loss = 2.2111151\n",
      "2018-04-13 19:48:27 iter 350 : loss_1 = -0.013354081 loss_2 = 0.20522352 loss_3 = 1.9996125 total_loss = 2.1914818\n",
      "2018-04-13 19:48:41 iter 400 : loss_1 = -0.00033892615 loss_2 = 0.18367614 loss_3 = 2.0722463 total_loss = 2.2555835\n",
      "2018-04-13 19:48:56 iter 450 : loss_1 = -0.0070392564 loss_2 = 0.1940109 loss_3 = 2.0356135 total_loss = 2.2225852\n",
      "2018-04-13 19:49:10 iter 500 : loss_1 = 0.0016632397 loss_2 = 0.18808708 loss_3 = 2.0840387 total_loss = 2.273789\n",
      "2018-04-13 19:49:25 iter 550 : loss_1 = -0.0006326285 loss_2 = 0.18431646 loss_3 = 1.9845665 total_loss = 2.1682503\n",
      "2018-04-13 19:49:39 iter 600 : loss_1 = -0.011765889 loss_2 = 0.19710413 loss_3 = 2.0012927 total_loss = 2.186631\n",
      "2018-04-13 19:49:53 iter 650 : loss_1 = 0.0065381015 loss_2 = 0.18410386 loss_3 = 2.0491667 total_loss = 2.2398086\n",
      "2018-04-13 19:50:08 iter 700 : loss_1 = -0.027572313 loss_2 = 0.21970078 loss_3 = 1.8961463 total_loss = 2.0882747\n",
      "2018-04-13 19:50:23 iter 750 : loss_1 = 0.003520549 loss_2 = 0.17487197 loss_3 = 2.063797 total_loss = 2.2421894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 19:50:37 iter 800 : loss_1 = -0.0038941994 loss_2 = 0.19214778 loss_3 = 2.0001504 total_loss = 2.188404\n",
      "2018-04-13 19:50:52 iter 850 : loss_1 = -0.0023754865 loss_2 = 0.18894058 loss_3 = 2.0305748 total_loss = 2.21714\n",
      "2018-04-13 19:50:55 iter 859 : loss_1 = -0.0063428194 loss_2 = 0.19309333 loss_3 = 2.0379355 total_loss = 2.224686\n",
      "2018-04-13 19:50:55 end epoch, average loss = 2.200668978607835\n",
      "2018-04-13 19:50:55 start epoch 23/100\n",
      "2018-04-13 19:50:55 iter 1 : loss_1 = 0.005145523 loss_2 = 0.17741421 loss_3 = 2.040583 total_loss = 2.2231426\n",
      "2018-04-13 19:51:09 iter 50 : loss_1 = -0.01676277 loss_2 = 0.20816994 loss_3 = 1.973248 total_loss = 2.1646552\n",
      "2018-04-13 19:51:24 iter 100 : loss_1 = -0.022270305 loss_2 = 0.20534329 loss_3 = 1.9724791 total_loss = 2.1555521\n",
      "2018-04-13 19:51:38 iter 150 : loss_1 = -0.012059224 loss_2 = 0.20498414 loss_3 = 1.9590943 total_loss = 2.1520193\n",
      "2018-04-13 19:51:53 iter 200 : loss_1 = -0.034936678 loss_2 = 0.21835461 loss_3 = 1.9214648 total_loss = 2.1048827\n",
      "2018-04-13 19:52:07 iter 250 : loss_1 = -0.0070281485 loss_2 = 0.19807585 loss_3 = 1.9809837 total_loss = 2.1720314\n",
      "2018-04-13 19:52:22 iter 300 : loss_1 = -0.01898045 loss_2 = 0.20574772 loss_3 = 1.9824808 total_loss = 2.169248\n",
      "2018-04-13 19:52:36 iter 350 : loss_1 = -0.0012378956 loss_2 = 0.19400999 loss_3 = 2.0281596 total_loss = 2.2209318\n",
      "2018-04-13 19:52:51 iter 400 : loss_1 = -0.007470429 loss_2 = 0.19305697 loss_3 = 2.042189 total_loss = 2.2277753\n",
      "2018-04-13 19:53:06 iter 450 : loss_1 = -0.019051963 loss_2 = 0.20231672 loss_3 = 2.0289958 total_loss = 2.2122605\n",
      "2018-04-13 19:53:21 iter 500 : loss_1 = 0.0067107663 loss_2 = 0.1766423 loss_3 = 2.1385794 total_loss = 2.3219323\n",
      "2018-04-13 19:53:35 iter 550 : loss_1 = -0.022095498 loss_2 = 0.21142069 loss_3 = 1.9455163 total_loss = 2.1348414\n",
      "2018-04-13 19:53:50 iter 600 : loss_1 = -0.004677754 loss_2 = 0.19130175 loss_3 = 2.064486 total_loss = 2.25111\n",
      "2018-04-13 19:54:04 iter 650 : loss_1 = -0.0060970252 loss_2 = 0.19411966 loss_3 = 2.0587692 total_loss = 2.2467918\n",
      "2018-04-13 19:54:19 iter 700 : loss_1 = -0.011543818 loss_2 = 0.19760118 loss_3 = 2.0097804 total_loss = 2.1958377\n",
      "2018-04-13 19:54:34 iter 750 : loss_1 = -0.032481156 loss_2 = 0.21958163 loss_3 = 1.944983 total_loss = 2.1320834\n",
      "2018-04-13 19:54:49 iter 800 : loss_1 = -0.017188523 loss_2 = 0.20642081 loss_3 = 1.9881592 total_loss = 2.1773915\n",
      "2018-04-13 19:55:03 iter 850 : loss_1 = 0.009853125 loss_2 = 0.17924657 loss_3 = 2.1166368 total_loss = 2.3057365\n",
      "2018-04-13 19:55:06 iter 859 : loss_1 = -0.0053075263 loss_2 = 0.20383048 loss_3 = 1.9960642 total_loss = 2.1945872\n",
      "2018-04-13 19:55:06 end epoch, average loss = 2.200894416835727\n",
      "2018-04-13 19:55:06 start epoch 24/100\n",
      "2018-04-13 19:55:06 iter 1 : loss_1 = -0.029854193 loss_2 = 0.22324498 loss_3 = 1.920748 total_loss = 2.1141388\n",
      "2018-04-13 19:55:21 iter 50 : loss_1 = 0.00067847443 loss_2 = 0.1907458 loss_3 = 2.0601296 total_loss = 2.251554\n",
      "2018-04-13 19:55:35 iter 100 : loss_1 = 0.0017387023 loss_2 = 0.19045009 loss_3 = 1.9736716 total_loss = 2.1658604\n",
      "2018-04-13 19:55:50 iter 150 : loss_1 = -0.02498148 loss_2 = 0.21401739 loss_3 = 1.9626455 total_loss = 2.1516814\n",
      "2018-04-13 19:56:05 iter 200 : loss_1 = -0.0041923253 loss_2 = 0.19044408 loss_3 = 2.0519333 total_loss = 2.238185\n",
      "2018-04-13 19:56:20 iter 250 : loss_1 = -0.008562367 loss_2 = 0.19797444 loss_3 = 2.0091646 total_loss = 2.1985767\n",
      "2018-04-13 19:56:34 iter 300 : loss_1 = 0.0065285116 loss_2 = 0.17939946 loss_3 = 2.0465512 total_loss = 2.232479\n",
      "2018-04-13 19:56:49 iter 350 : loss_1 = -0.013645837 loss_2 = 0.20439558 loss_3 = 1.9641272 total_loss = 2.154877\n",
      "2018-04-13 19:57:04 iter 400 : loss_1 = -0.021105308 loss_2 = 0.20303588 loss_3 = 1.9925785 total_loss = 2.174509\n",
      "2018-04-13 19:57:19 iter 450 : loss_1 = -0.007860463 loss_2 = 0.19988255 loss_3 = 2.0324574 total_loss = 2.2244794\n",
      "2018-04-13 19:57:34 iter 500 : loss_1 = -0.0028011515 loss_2 = 0.18531236 loss_3 = 2.0498016 total_loss = 2.2323127\n",
      "2018-04-13 19:57:48 iter 550 : loss_1 = -0.006661743 loss_2 = 0.1925909 loss_3 = 1.979198 total_loss = 2.165127\n",
      "2018-04-13 19:58:03 iter 600 : loss_1 = -0.028172588 loss_2 = 0.21237607 loss_3 = 1.9413842 total_loss = 2.1255877\n",
      "2018-04-13 19:58:18 iter 650 : loss_1 = 0.0067350566 loss_2 = 0.18013696 loss_3 = 2.0658898 total_loss = 2.2527618\n",
      "2018-04-13 19:58:33 iter 700 : loss_1 = 0.00733338 loss_2 = 0.18389241 loss_3 = 2.038296 total_loss = 2.2295218\n",
      "2018-04-13 19:58:48 iter 750 : loss_1 = 0.005686303 loss_2 = 0.19394574 loss_3 = 2.0016022 total_loss = 2.201234\n",
      "2018-04-13 19:59:02 iter 800 : loss_1 = -0.0035072316 loss_2 = 0.20281574 loss_3 = 1.9533232 total_loss = 2.1526318\n",
      "2018-04-13 19:59:17 iter 850 : loss_1 = -0.0037641495 loss_2 = 0.19679943 loss_3 = 2.0143442 total_loss = 2.2073796\n",
      "2018-04-13 19:59:20 iter 859 : loss_1 = -0.03633707 loss_2 = 0.23337486 loss_3 = 1.8899976 total_loss = 2.0870354\n",
      "2018-04-13 19:59:20 end epoch, average loss = 2.2016399689409036\n",
      "2018-04-13 19:59:20 start epoch 25/100\n",
      "2018-04-13 19:59:20 iter 1 : loss_1 = -0.017999807 loss_2 = 0.20958833 loss_3 = 1.9577081 total_loss = 2.1492968\n",
      "2018-04-13 19:59:35 iter 50 : loss_1 = -0.00083505607 loss_2 = 0.19824836 loss_3 = 2.0052133 total_loss = 2.2026265\n",
      "2018-04-13 19:59:50 iter 100 : loss_1 = 0.014375311 loss_2 = 0.1727714 loss_3 = 2.107999 total_loss = 2.2951458\n",
      "2018-04-13 20:00:05 iter 150 : loss_1 = -0.030203605 loss_2 = 0.21458617 loss_3 = 1.9357823 total_loss = 2.1201649\n",
      "2018-04-13 20:00:19 iter 200 : loss_1 = -0.0049424903 loss_2 = 0.19653605 loss_3 = 1.9821517 total_loss = 2.1737454\n",
      "2018-04-13 20:00:34 iter 250 : loss_1 = -0.022996768 loss_2 = 0.21380043 loss_3 = 2.0313072 total_loss = 2.222111\n",
      "2018-04-13 20:00:49 iter 300 : loss_1 = -0.026641052 loss_2 = 0.21661691 loss_3 = 1.955985 total_loss = 2.1459608\n",
      "2018-04-13 20:01:05 iter 350 : loss_1 = -0.020394389 loss_2 = 0.2074246 loss_3 = 2.0101542 total_loss = 2.1971846\n",
      "2018-04-13 20:01:20 iter 400 : loss_1 = -0.023449365 loss_2 = 0.21529344 loss_3 = 1.9150865 total_loss = 2.1069305\n",
      "2018-04-13 20:01:35 iter 450 : loss_1 = -0.004297799 loss_2 = 0.19415103 loss_3 = 2.01048 total_loss = 2.200333\n",
      "2018-04-13 20:01:50 iter 500 : loss_1 = -0.008874466 loss_2 = 0.20016699 loss_3 = 1.9516766 total_loss = 2.1429691\n",
      "2018-04-13 20:02:06 iter 550 : loss_1 = -0.01997844 loss_2 = 0.21136999 loss_3 = 1.9851385 total_loss = 2.1765301\n",
      "2018-04-13 20:02:21 iter 600 : loss_1 = -0.013349968 loss_2 = 0.20635276 loss_3 = 1.9692519 total_loss = 2.1622546\n",
      "2018-04-13 20:02:36 iter 650 : loss_1 = -0.012427684 loss_2 = 0.20022455 loss_3 = 1.967308 total_loss = 2.1551049\n",
      "2018-04-13 20:02:51 iter 700 : loss_1 = -0.0019040473 loss_2 = 0.19575426 loss_3 = 2.0205116 total_loss = 2.214362\n",
      "2018-04-13 20:03:07 iter 750 : loss_1 = -0.012018171 loss_2 = 0.19531345 loss_3 = 1.9722371 total_loss = 2.1555324\n",
      "2018-04-13 20:03:22 iter 800 : loss_1 = -0.011228721 loss_2 = 0.20033602 loss_3 = 2.027495 total_loss = 2.2166023\n",
      "2018-04-13 20:03:37 iter 850 : loss_1 = -0.0116564175 loss_2 = 0.20634708 loss_3 = 2.007236 total_loss = 2.2019267\n",
      "2018-04-13 20:03:40 iter 859 : loss_1 = -0.024762888 loss_2 = 0.21062914 loss_3 = 1.9197752 total_loss = 2.1056416\n",
      "2018-04-13 20:03:40 end epoch, average loss = 2.202783242926192\n",
      "2018-04-13 20:03:40 start epoch 26/100\n",
      "2018-04-13 20:03:40 iter 1 : loss_1 = -0.008685024 loss_2 = 0.19721496 loss_3 = 2.019668 total_loss = 2.208198\n",
      "2018-04-13 20:03:56 iter 50 : loss_1 = -0.003530803 loss_2 = 0.19394146 loss_3 = 2.0177636 total_loss = 2.2081742\n",
      "2018-04-13 20:04:11 iter 100 : loss_1 = 0.009009248 loss_2 = 0.17812629 loss_3 = 2.0426562 total_loss = 2.2297916\n",
      "2018-04-13 20:04:26 iter 150 : loss_1 = -0.00272283 loss_2 = 0.19029881 loss_3 = 2.018354 total_loss = 2.20593\n",
      "2018-04-13 20:04:42 iter 200 : loss_1 = -0.037065167 loss_2 = 0.22803418 loss_3 = 1.9053371 total_loss = 2.096306\n",
      "2018-04-13 20:04:57 iter 250 : loss_1 = 0.008998359 loss_2 = 0.18671337 loss_3 = 2.0134292 total_loss = 2.2091408\n",
      "2018-04-13 20:05:12 iter 300 : loss_1 = -0.028147375 loss_2 = 0.21572605 loss_3 = 1.9533386 total_loss = 2.1409173\n",
      "2018-04-13 20:05:28 iter 350 : loss_1 = -0.021765767 loss_2 = 0.21233587 loss_3 = 1.9047766 total_loss = 2.0953467\n",
      "2018-04-13 20:05:43 iter 400 : loss_1 = -0.008880636 loss_2 = 0.19839989 loss_3 = 2.0182147 total_loss = 2.2077339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-13 20:05:58 iter 450 : loss_1 = -0.010209637 loss_2 = 0.204074 loss_3 = 2.0210824 total_loss = 2.2149467\n",
      "2018-04-13 20:06:14 iter 500 : loss_1 = -0.004381531 loss_2 = 0.19995503 loss_3 = 2.0162354 total_loss = 2.211809\n",
      "2018-04-13 20:06:29 iter 550 : loss_1 = 0.010647161 loss_2 = 0.17880674 loss_3 = 2.049679 total_loss = 2.239133\n",
      "2018-04-13 20:06:45 iter 600 : loss_1 = -0.0065267035 loss_2 = 0.19162194 loss_3 = 2.0534637 total_loss = 2.238559\n",
      "2018-04-13 20:07:00 iter 650 : loss_1 = -0.012475845 loss_2 = 0.20185924 loss_3 = 2.0412145 total_loss = 2.230598\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c4aa9a48f9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             loss_1,loss_2,loss_3,loss_out,_=sess.run([reinforce_llh,baseline_mse,softmax_loss,loss,train_step],\n\u001b[0;32m---> 19\u001b[0;31m                                                      feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mtot_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epoch=100\n",
    "print_every=50\n",
    "num_iteration=num_train//batch_size\n",
    "loss_his=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     print(tf.global_variables())\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(max_epoch):\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'start epoch %d/%d' % (epoch+1,max_epoch))\n",
    "        tot_loss=0\n",
    "        for it in range(num_iteration):\n",
    "            images,labels=mnist.train.next_batch(batch_size)\n",
    "            # prepare data for monte carlo test\n",
    "            images=np.tile(images,(MC_test,1))\n",
    "            labels=np.tile(labels,(MC_test,1))\n",
    "            feed_dict={X:images.reshape(tot_size,28,28,1),y:labels}\n",
    "            loss_1,loss_2,loss_3,loss_out,_=sess.run([reinforce_llh,baseline_mse,softmax_loss,loss,train_step],\n",
    "                                                     feed_dict=feed_dict)\n",
    "            tot_loss+=loss_out\n",
    "            if it==0 or (it+1)%print_every==0 or it==num_iteration-1:\n",
    "                print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
    "                      'iter',it+1,': loss_1 =',loss_1,'loss_2 =',loss_2,'loss_3 =',loss_3,'total_loss =',loss_out)\n",
    "        loss_his.append(tot_loss/num_iteration)\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
    "              'end epoch, average loss =',(tot_loss/num_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "ptr,=plt.plot(range(max_epoch),loss_his)\n",
    "plt.xlabel('training epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean=tf.zeros((100,2),dtype=tf.float32)\n",
    "# std=tf.constant([1,1],dtype=tf.float32)\n",
    "# gaussian=tf.distributions.Normal(loc=mean,scale=std)\n",
    "# rand=tf.random_normal(shape=(100,2),mean=0,stddev=1)\n",
    "# sampled=mean+rand\n",
    "# prob=-gaussian.log_prob(sampled)\n",
    "# prob=tf.reduce_mean(tf.reduce_sum(prob,1))\n",
    "# with tf.Session() as sess:\n",
    "#     out=sess.run([prob])\n",
    "#     print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
